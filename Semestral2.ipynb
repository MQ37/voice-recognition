{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a9510f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyttsx3\n",
    "import os\n",
    "import scipy.io.wavfile\n",
    "import scipy.signal\n",
    "import scipy.spatial.distance\n",
    "import librosa\n",
    "import librosa.display\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66558a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS = [\n",
    "    \"time\", \"prepare\", \"solution\", \"make\", \"mistake\", \"no\", \"the\", \"probable\", \"long\", \"lecture\",\n",
    "    \"method\", \"disaster\", \"fail\", \"work\", \"advice\", \"idea\", \"succeed\", \"easy\", \"is\", \"for\", \"give\",\n",
    "    \"to\" # Added word \"to\" which is not in assingment list but appears in the audio\n",
    "]\n",
    "\n",
    "WORDS_DIR = \"words/\"\n",
    "\n",
    "# the work easy the time long to prepare the solution\n",
    "SOLUTION = [\"the\", \"work\", \"easy\", \"the\", \"time\", \"long\", \"to\", \"prepare\", \"the\", \"solution\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16197789",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate words WAV files\n",
    "\n",
    "if not os.path.exists(WORDS_DIR):\n",
    "    os.mkdir(WORDS_DIR)\n",
    "    \n",
    "engine = pyttsx3.init()\n",
    "for word in WORDS:\n",
    "    # skip existing\n",
    "    if os.path.exists(os.path.join(WORDS_DIR, \"%s.wav\" % word)):\n",
    "        continue\n",
    "    engine.save_to_file(word, os.path.join(WORDS_DIR, \"%s.wav\" % word))\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b6d315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper functions\n",
    "\n",
    "def trim_signal(s1, trim_threshold=10):\n",
    "    s1[(-trim_threshold < s1) & (s1 < trim_threshold)] = 0\n",
    "    ts1 = np.trim_zeros(s1)\n",
    "    return ts1\n",
    "    \n",
    "def trim_pad_pair(s1, s2, trim_threshold=10):\n",
    "    ts1 = trim_signal(s1)\n",
    "    ts2 = trim_signal(s2)\n",
    "    msize = max(ts1.size, ts2.size)\n",
    "    psize = (msize // 1000 + 1)*1000\n",
    "    ps1 = np.pad(ts1, (0, psize - ts1.size))\n",
    "    ps2 = np.pad(ts2, (0, psize - ts2.size))\n",
    "    \n",
    "    return ps1, ps2\n",
    "\n",
    "def load_file(filename):\n",
    "    fs, s = scipy.io.wavfile.read(filename)\n",
    "    s = trim_signal(s)\n",
    "    return fs, s.astype(np.float64)\n",
    "\n",
    "def load_word(word):\n",
    "    filename = os.path.join(WORDS_DIR, \"%s.wav\" % word)\n",
    "    return load_file(filename)\n",
    "\n",
    "def write_wav(data, filename, rate=22050): \n",
    "    scipy.io.wavfile.write(filename, rate, data)\n",
    "    \n",
    "def split_data(data, window_size=1000, threshold=1600):\n",
    "    data = copy.deepcopy(data)\n",
    "    \n",
    "    base = 0\n",
    "    is_voice = False\n",
    "    n_empty = 0\n",
    "    \n",
    "    msize = data.size\n",
    "    psize = (msize // window_size + 1)*window_size\n",
    "    data = np.pad(data, (0, psize - data.size))\n",
    "\n",
    "    parts = []\n",
    "\n",
    "    for i, window in enumerate(np.split(data, data.size / window_size)):\n",
    "        #_sum = np.sum(np.abs(window))\n",
    "        _max = np.max(np.abs(window))\n",
    "        if n_empty > 1 and is_voice:\n",
    "            part = data[base:(i+1)*window_size]\n",
    "            part = trim_signal(part)\n",
    "            parts.append(part)\n",
    "\n",
    "            base = (i+1)*window_size\n",
    "            is_voice = False\n",
    "            n_empty = 0\n",
    "        elif _max >= threshold and not is_voice:\n",
    "            is_voice = True\n",
    "        elif _max < threshold and is_voice:\n",
    "            n_empty += 1\n",
    "            \n",
    "    if not parts:\n",
    "        return [data]\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e335508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD data\n",
    "\n",
    "data = np.loadtxt(\"Signal1.txt\")\n",
    "#data = data[:data.size - data.size%1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7b6aa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split data\n",
    "parts = split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5d09643",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the ('the', 0.936) ('give', 0.934) ('is', 0.93)\n",
      "work ('work', 0.954) ('make', 0.938) ('no', 0.937)\n",
      "easy ('easy', 0.947) ('long', 0.947) ('fail', 0.944)\n",
      "the ('the', 0.935) ('give', 0.932) ('is', 0.93)\n",
      "time ('time', 0.954) ('fail', 0.952) ('long', 0.947)\n",
      "long ('no', 0.958) ('long', 0.952) ('work', 0.951)\n",
      "to ('the', 0.949) ('to', 0.935) ('give', 0.931)\n",
      "prepare ('prepare', 0.957) ('idea', 0.945) ('probable', 0.919)\n",
      "the ('the', 0.935) ('give', 0.932) ('is', 0.931)\n",
      "solution ('solution', 0.949) ('disaster', 0.939) ('probable', 0.922)\n",
      "Correct: 8/10 (80.0%)\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for answer, Y in zip(SOLUTION, parts):\n",
    "    similarities = []\n",
    "    for i, word in enumerate(WORDS):\n",
    "        sr, X = load_word(word)\n",
    "        pX, pY = trim_pad_pair(X, Y)\n",
    "        #X *= np.hamming(X.size)\n",
    "\n",
    "        ###f, t, Sxx1 = scipy.signal.spectrogram(pX, sr)\n",
    "        ###f, t, Sxx2 = scipy.signal.spectrogram(pY, sr)\n",
    "        ###dist_spec = scipy.spatial.distance.cosine(Sxx1.flatten(), Sxx2.flatten())\n",
    "\n",
    "        #dist, cost, acc_cost, path = dtw(pX, pY, dist=lambda x, y: np.linalg.norm(x - y, ord=1))\n",
    "        #similarity = dist\n",
    "        \n",
    "        # Mel spectrum\n",
    "        sX = librosa.feature.melspectrogram(y=pX, sr=sr, n_fft=512)\n",
    "        # Mel cepstrum coefs\n",
    "        mfccsX = librosa.feature.mfcc(S=librosa.power_to_db(sX))\n",
    "        sY = librosa.feature.melspectrogram(y=pY, sr=sr, n_fft=512)\n",
    "        mfccsY = librosa.feature.mfcc(S=librosa.power_to_db(sY))\n",
    "        dist_mfccs = scipy.spatial.distance.cosine(mfccsX.flatten(), mfccsY.flatten())\n",
    "        \n",
    "        ###fftX = np.fft.fft(pX)\n",
    "        ###fftY = np.fft.fft(pY)\n",
    "        ###dist_fft = scipy.spatial.distance.cosine(fftX,  fftY)\n",
    "        \n",
    "        #cqtX = librosa.cqt(pX)\n",
    "        #cqtY = librosa.cqt(pY)\n",
    "        #dist_cqt = scipy.spatial.distance.cosine(cqtX.flatten(), cqtY.flatten())\n",
    "        \n",
    "        #stftX = np.abs(librosa.stft(pX, n_fft=512))\n",
    "        #stftX = librosa.amplitude_to_db(stftX, ref=np.max)\n",
    "        #stftY = np.abs(librosa.stft(pY, n_fft=512))\n",
    "        #stftY = librosa.amplitude_to_db(stftY, ref=np.max)\n",
    "        #dist_stft = scipy.spatial.distance.cosine(stftX.flatten(), stftY.flatten())\n",
    "\n",
    "        #similarity = dist_spec + dist_mfccs + dist_fft + dist_cqt + dist_stft\n",
    "        similarity = dist_mfccs\n",
    "\n",
    "        similarities.append( (word, similarity) )\n",
    "    \n",
    "    guess = sorted(similarities, key=lambda x: x[1])[0:3]\n",
    "    # Convert to likelihood\n",
    "    guess = [(x[0], np.round(1-x[1], 3)) for x in guess]\n",
    "    #guess = [x[0] for x in guess]\n",
    "    #print(answer, [x[0] for x in guess])\n",
    "    print(answer, *guess)\n",
    "    if answer == guess[0][0]:\n",
    "        correct += 1\n",
    "        \n",
    "correct_percentage = correct / len(parts) * 100\n",
    "print(\"Correct: %s/%s (%s%%)\" % (correct, len(parts), correct_percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539fe880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
